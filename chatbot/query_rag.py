import os
import io
import base64
import uuid
import gridfs
import pytz
import hashlib
import google.genai as genai
import google.genai.types as types
from chatbot import config as app_config

from datetime import datetime, timezone
from pymongo import MongoClient, ASCENDING, DESCENDING
from bson.objectid import ObjectId
from PIL import Image

# --- LangChain Imports ---
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables import RunnableLambda, ConfigurableFieldSpec
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate

# ==============================================================================
# SECTION 1: KH·ªûI T·∫†O C√ÅC TH√ÄNH PH·∫¶N TO√ÄN C·ª§C (GLOBAL COMPONENTS)
# ==============================================================================

# --- MONGODB CONNECTION ---
try:
    _mongo_client = MongoClient(app_config.MONGO_URI, serverSelectionTimeoutMS=5000, connectTimeoutMS=5000)
    _mongo_client.admin.command('ping')
    print("MongoDB ping successful.")

    _mongo_db = _mongo_client[app_config.MONGO_DB_NAME]
    DB_COLLECTION = _mongo_db["sessions"]
    FS = gridfs.GridFS(_mongo_db)

    DB_COLLECTION.create_index([("session_id", ASCENDING)], unique=True)
    DB_COLLECTION.create_index([("updated_at", DESCENDING)])
    print(f"Connected successfully to MongoDB and GridFS.")
except Exception as e:
    print(f"Failed to connect to MongoDB: {e}")
    DB_COLLECTION, FS, _mongo_db = None, None, None

# --- GOOGLE AI SDK CLIENT (M·ªöI) ---
try:
    GLOBAL_GENAI_CLIENT = genai.Client()
    print("Google Generative AI SDK client initialized.")
except Exception as e:
    print(f"L·ªói khi c·∫•u h√¨nh Google AI SDK client: {e}")
    GLOBAL_GENAI_CLIENT = None


def get_mongo_collection(collection_name: str = "sessions"):
    """Tr·∫£ v·ªÅ collection 'sessions' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o."""
    if _mongo_client is None or _mongo_db is None:
        print(f"L·ªói: K·∫øt n·ªëi MongoDB ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p")
        return None
    try:
        return _mongo_db[collection_name]
    except Exception as ex:
        print(f"L·ªói khi l·∫•y collection '{collection_name}': {ex}")
        return None


try:
    DB_DOCUMENTS_COLLECTION = get_mongo_collection("documents")
    if DB_DOCUMENTS_COLLECTION is not None:
        DB_DOCUMENTS_COLLECTION.create_index([("session_id", ASCENDING)])
        DB_DOCUMENTS_COLLECTION.create_index([("user_id", ASCENDING)])
        DB_DOCUMENTS_COLLECTION.create_index([("created_at", DESCENDING)])
        print("MongoDB collection 'documents' initialized.")
except Exception as e:
    print(f"Failed to initialize 'documents' collection: {e}")
    DB_DOCUMENTS_COLLECTION = None


def check_session_belongs_to_user(session_id: str, user_id: str) -> bool:
    """Ki·ªÉm tra session c√≥ t·ªìn t·∫°i v√† thu·ªôc v·ªÅ user_id kh√¥ng."""
    coll = get_mongo_collection("sessions")  # L·∫•y collection sessions
    if coll is None:
        return False
    try:
        # ƒê·∫øm s·ªë document kh·ªõp c·∫£ session_id v√† user_id
        return coll.count_documents({"session_id": session_id, "user_id": user_id}, limit=1) > 0
    except Exception as e:
        print(f"L·ªói khi ki·ªÉm tra session ownership: {e}")
        return False


# --- VIETNAM TIMEZONE DEFINITION (Gi·ªØ nguy√™n) ---
try:
    VN_TZ = pytz.timezone("Asia/Ho_Chi_Minh")
    print("VN_TZ initialized successfully.")
except pytz.UnknownTimeZoneError:
    VN_TZ = timezone.utc


# --- LLM MODEL (Gi·ªØ nguy√™n) ---
def initialize_llm(model_name, temperature):
    return ChatGoogleGenerativeAI(
        model=model_name,
        temperature=temperature
    )


try:
    TEXT_LLM = initialize_llm(app_config.TEXT_MODEL_NAME, 0.1)
    VISION_LLM = initialize_llm(app_config.VISION_MODEL_NAME, 0.1)
    print("LLM (LangChain) models initialized successfully.")
except Exception as e:
    print(f"‚ùå Failed to initialize LLMs: {e}")
    TEXT_LLM, VISION_LLM = None, None


# ==============================================================================
# SECTION 2: C√ÅC H√ÄM TI·ªÜN √çCH C·ªêT L√ïI (CORE UTILITY FUNCTIONS)
# ==============================================================================
def format_chat_history(history):
    """Format l·ªãch s·ª≠ chat th√†nh chu·ªói vƒÉn b·∫£n ƒë·ªÉ ƒë∆∞a v√†o prompt."""
    if not history:
        return "No previous messages."
    formatted_parts = []
    for message in history:
        role = getattr(message, 'role', str(type(message).__name__))
        content = getattr(message, 'content', str(message))
        if isinstance(content, list):
            # X·ª≠ l√Ω n·ªôi dung multimodal (ch·ªâ l·∫•y text)
            text_content = ""
            for part in content:
                if isinstance(part, dict) and part.get("type") == "text":
                    text_content = part.get("text", "")
                    break
            content = text_content
        formatted_parts.append(f"{role.upper()}: {content}")
    return "\n\n".join(formatted_parts)


def extract_citations(response, show_details=False):
    """Tr√≠ch xu·∫•t v√† format ngu·ªìn tr√≠ch d·∫´n t·ª´ response metadata.

    Args:
        response: Response t·ª´ Google AI
        show_details: N·∫øu True, hi·ªÉn th·ªã th√™m th√¥ng tin chi ti·∫øt (s·ªë ƒëo·∫°n tr√≠ch d·∫´n)
    """
    try:
        metadata = response.candidates[0].grounding_metadata
        if not (metadata and metadata.grounding_supports and metadata.grounding_chunks):
            return ""  # Kh√¥ng c√≥ tr√≠ch d·∫´n

        all_chunks = metadata.grounding_chunks
        file_citation_count = {}

        # ƒê·∫øm s·ªë l∆∞·ª£ng tr√≠ch d·∫´n cho m·ªói file
        for support in metadata.grounding_supports:
            for chunk_index in support.grounding_chunk_indices:
                if 0 <= chunk_index < len(all_chunks):
                    chunk = all_chunks[chunk_index]
                    filename = chunk.retrieved_context.title
                    file_citation_count[filename] = file_citation_count.get(filename, 0) + 1

        if not file_citation_count:
            return ""

        # Format ph·∫ßn citations
        citations_str = "\n\n--- üìö Ngu·ªìn tham kh·∫£o ---\n"
        for filename, count in file_citation_count.items():
            if show_details:
                citations_str += f"üìÑ {filename} (tr√≠ch d·∫´n {count} ƒëo·∫°n)"
            else:
                citations_str += f"üìÑ {filename}"

        return citations_str
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t citations: {e}")
        return ""


def save_session_message(session_id, user_id, question, answer, image_path=None):
    """L∆∞u c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi v√†o MongoDB (b·∫£n t·ªëi ∆∞u)."""
    coll = get_mongo_collection()
    fs_client = FS
    if coll is None or fs_client is None:
        print("L·ªói: Kh√¥ng th·ªÉ l∆∞u session, DB ho·∫∑c GridFS ch∆∞a k·∫øt n·ªëi.")
        return

    now = datetime.now(VN_TZ).isoformat()

    image_gridfs_id = None

    if image_path and os.path.exists(image_path):
        try:
            with open(image_path, "rb") as i_f:
                image_gridfs_id = fs_client.put(
                    i_f,
                    filename=os.path.basename(image_path),
                    metadata={
                        "session_id": session_id,
                        "user_id": user_id,
                        "upload_time": now
                    }
                )
        except Exception as img_ex:
            print(f"L·ªói khi l∆∞u ·∫£nh v√†o GridFS: {img_ex}")

    message_data = {
        "question": question,
        "answer": answer,
        "image_gridfs_id": str(image_gridfs_id) if image_gridfs_id else None,
        "timestamp": now
    }

    coll.update_one(
        {"session_id": session_id},
        {
            "$push": {"messages": message_data},
            "$set": {"updated_at": now},
            "$setOnInsert": {
                "user_id": user_id,
                "created_at": now
            }
        },
        upsert=True
    )


def load_session_messages(session_id, user_id, limit=100):
    """Load messages c·ªßa session c·ª• th·ªÉ theo user_id."""
    coll = get_mongo_collection()
    if coll is None:
        return InMemoryChatMessageHistory()
    session = coll.find_one({"session_id": session_id, "user_id": user_id})
    if session and "messages" in session:
        memory = InMemoryChatMessageHistory()
        for msg in session["messages"][-limit:]:
            question = msg.get("question", "")
            answer = msg.get("answer", "")
            if question:
                memory.add_message(HumanMessage(content=question))
            if answer:
                memory.add_message(AIMessage(content=answer))
        return memory
    return InMemoryChatMessageHistory()


def list_sessions(limit=20, user_id=None):
    """L·∫•y danh s√°ch session t·ª´ MongoDB, l·ªçc theo user_id n·∫øu c√≥."""
    coll = get_mongo_collection()
    if coll is None:
        print("L·ªói: MongoDB ch∆∞a k·∫øt n·ªëi.")
        return []
    query = {"user_id": user_id} if user_id else {}
    sessions = coll.find(query, projection={"session_id": 1, "created_at": 1, "updated_at": 1, "user_id": 1,
                                            "messages": 1}).sort("updated_at", DESCENDING).limit(limit)
    result_list = []
    for s in sessions:
        num_msgs = len(s.get("messages", []))
        result_list.append({"session_id": s["session_id"], "created_at": s.get("created_at", "N/A"),
                            "updated_at": s.get("updated_at", "N/A"), "user_id": s.get("user_id", "N/A"),
                            "num_messages": num_msgs})
    return result_list


def list_documents_by_user(user_id: str, limit: int = 50):
    coll = DB_DOCUMENTS_COLLECTION
    if coll is None:
        print("L·ªói: MongoDB ch∆∞a k·∫øt n·ªëi.")
        return []
    try:
        docs_cursor = coll.find(
            {"user_id": user_id},
            projection={
                "_id": 1,
                "session_id": 1,
                "filename": 1,
                "created_at": 1,
                "status": 1,
                "file_store_name": 1,
                "file_hash": 1
            }
        ).sort("created_at", DESCENDING).limit(limit)
        documents = []
        for doc in docs_cursor:
            documents.append({
                "id": str(doc["_id"]),
                "session_id": doc.get("session_id", "N/A"),
                "filename": doc.get("filename", "N/A"),
                "created_at": doc.get("created_at", "N/A"),
                "status": doc.get("status", "N/A"),
                "file_store_name": doc.get("file_store_name", ""),
                "file_hash": doc.get("file_hash", "")
            })
        return documents
    except Exception as e:
        print(f"L·ªói khi l·∫•y danh s√°ch documents theo user: {e}")
        return []


def get_session_file_store(session_id: str) -> str | None:
    """L·∫§Y FILE STORE C·ª¶A SESSION - FIXED: Ki·ªÉm tra None tr∆∞·ªõc khi d√πng"""
    coll = DB_DOCUMENTS_COLLECTION
    if coll is None:
        return None
    try:
        doc_record = coll.find_one(
            {"session_id": session_id, "status": "processed"},
            projection={"file_store_name": 1}
        )
        if doc_record and "file_store_name" in doc_record:
            return doc_record.get("file_store_name")
        return None
    except Exception as e:
        print(f"L·ªói khi l·∫•y session file store: {e}")
        return None


def compute_file_hash(file_path: str) -> str:
    """T·∫°o hash MD5 cho file ƒë·ªÉ tr√°nh tr√πng."""
    with open(file_path, "rb") as f:
        file_data = f.read()
    return hashlib.md5(file_data).hexdigest()


def save_pdf_to_mongo(file_path: str, session_id: str, user_id: str) -> str | None:
    fs_client = FS
    coll = DB_DOCUMENTS_COLLECTION
    if fs_client is None or coll is None:
        print("L·ªói: Kh√¥ng th·ªÉ l∆∞u file, DB ho·∫∑c GridFS ch∆∞a k·∫øt n·ªëi.")
        return None
    try:
        file_hash = compute_file_hash(file_path)
        # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i v√† x·ª≠ l√Ω xong ch∆∞a
        existing = coll.find_one({"file_hash": file_hash, "user_id": user_id, "status": "processed"})
        if existing:
            print(f"File ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n v√† x·ª≠ l√Ω. File Store: {existing.get('file_store_name')}")
            coll.update_one(
                {"_id": existing["_id"]},
                {"$addToSet": {"sessions": session_id}}
            )
            return str(existing["_id"])
        now = datetime.now(VN_TZ).isoformat()
        with open(file_path, "rb") as f:
            file_id = fs_client.put(f, filename=os.path.basename(file_path))
        doc_data = {
            "user_id": user_id,
            "session_id": session_id,
            "sessions": [session_id],
            "filename": os.path.basename(file_path),
            "file_gridfs_id": str(file_id),
            "file_hash": file_hash,
            "created_at": now,
            "status": "uploaded"
        }
        result = coll.insert_one(doc_data)
        print(f"ƒê√£ l∆∞u file v√†o DB v·ªõi document ID: {result.inserted_id}")
        return str(result.inserted_id)
    except Exception as e:
        print(f"L·ªói khi l∆∞u file v√†o DB: {e}")
        return None


def process_and_vectorize_pdf(file_path: str, session_id: str, user_id: str):
    """
    Upload PDF l√™n Google File Search Tool, t·∫°o File Store t·ª± ƒë·ªông cho session.
    """
    coll = DB_DOCUMENTS_COLLECTION
    client = GLOBAL_GENAI_CLIENT
    if coll is None or client is None:
        print("L·ªói: Thi·∫øu MongoDB ho·∫∑c Google AI client.")
        return

    file_name = os.path.basename(file_path)
    print(f"ƒêang x·ª≠ l√Ω file {file_name} v·ªõi Google File Search Tool...")

    try:
        store_display_name = f"session-store-{session_id[:16]}-{uuid.uuid4().hex[:12]}"
        file_store = client.file_search_stores.create(
            config={'display_name': store_display_name}
        )
        store_name = file_store.name
        print(f"T·∫°o th√†nh c√¥ng File Store: {store_name}")

        print(f"ƒêang t·∫£i file {file_name} l√™n store...")
        client.file_search_stores.upload_to_file_search_store(
            file=file_path,
            file_search_store_name=store_name,
            config={'display_name': file_name}
        )
        print("T·∫£i file l√™n th√†nh c√¥ng.")

        DB_DOCUMENTS_COLLECTION.update_one(
            {"session_id": session_id, "filename": file_name, "user_id": user_id},
            {"$set": {"status": "processed", "file_store_name": store_name}}
        )
        print(f"ƒê√£ c·∫≠p nh·∫≠t MongoDB, li√™n k·∫øt session v·ªõi store: {store_name}")
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω file v·ªõi Google File Search: {e}")
        DB_DOCUMENTS_COLLECTION.update_one(
            {"session_id": session_id, "filename": file_name, "user_id": user_id},
            {"$set": {"status": "error_processing"}}
        )


def delete_session_and_associated_files(session_id: str, user_id: str) -> dict:
    """

    :param session_id:
    :param user_id:
    :return:
    """
    sessions_coll = get_mongo_collection("sessions")
    docs_coll = DB_DOCUMENTS_COLLECTION
    fs_client = FS
    client = GLOBAL_GENAI_CLIENT
    if sessions_coll is None or fs_client is None or client is None or docs_coll is None:
        raise Exception("M·ªôt ho·∫∑c nhi·ªÅu th√†nh ph·∫ßn DB (Mongo, GridFS, client) ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")

    deleted_counts = {
        "sessions": 0,
        "document_records": 0,
        "gridfs_files": 0,
        "file_stores": 0
    }

    gridfs_ids_to_delete, file_store_names_to_delete = [], set()

    try:
        session_doc = sessions_coll.find_one({"session_id": session_id, "user_id": user_id})
        if session_doc:
            for msg in session_doc.get("messages", []):
                if msg.get("image_gridfs_id"):
                    try:
                        gridfs_ids_to_delete.append(ObjectId(msg["image_gridfs_id"]))
                    except Exception:
                        pass
            session_delete = sessions_coll.delete_one({"_id": session_doc["_id"]})
            deleted_counts["sessions"] = session_delete.deleted_count
            print(f"ƒê√£ x√≥a session '{session_id}' kh·ªèi collection 'sessions'.")
    except Exception as e:
        print(f"L·ªói khi x√≥a session: {e}")

    try:
        doc_records = docs_coll.find({"session_id": session_id, "user_id": user_id})
        for doc in doc_records:
            if doc.get("file_gridfs_id"):
                try:
                    gridfs_ids_to_delete.append(ObjectId(doc["file_gridfs_id"]))
                except Exception:
                    pass
            if doc.get("file_store_name"):
                file_store_names_to_delete.add(doc["file_store_name"])
        doc_delete = docs_coll.delete_many({"session_id": session_id, "user_id": user_id})
        deleted_counts["document_records"] = doc_delete.deleted_count
        print(f"ƒê√£ x√≥a {deleted_counts['document_records']} document records c·ªßa session.")
    except Exception as e:
        print(f"L·ªói khi x√≥a document records: {e}")

    for gf_id in gridfs_ids_to_delete:
        try:
            fs_client.delete(gf_id)
            deleted_counts["gridfs_files"] += 1
        except Exception as e:
            print(f"L·ªói khi x√≥a GridFS file {gf_id}: {e}")

    for store_name in file_store_names_to_delete:
        try:
            client.file_search_stores.delete(name=store_name)
            deleted_counts["file_stores"] += 1
            print(f"ƒê√£ x√≥a File Store: {store_name}")
        except Exception as e:
            print(f"L·ªói khi x√≥a File Store {store_name}: {e}")
    return deleted_counts


def image_to_base64(image_path, max_size_px=1024, jpeg_quality=85):
    """Chuy·ªÉn file ·∫£nh sang chu·ªói base64, ƒë·ªìng th·ªùi
    resize v√† n√©n ·∫£nh ƒë·ªÉ t·ªëi ∆∞u chi ph√≠ v√† t·ªëc ƒë·ªô.
    """
    try:
        with Image.open(image_path) as img:
            img.thumbnail((max_size_px, max_size_px))

            if img.mode != 'RGB':
                img = img.convert('RGB')

            buffered = io.BytesIO()
            img.save(
                buffered,
                format="JPEG",
                quality=jpeg_quality,
                optimize=True
            )
            return base64.b64encode(buffered.getvalue()).decode("utf-8")
    except Exception as e:
        print(f"L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
        return None


# --- MEMORY MANAGEMENT ---
def get_session_history(session_id: str, user_id: str):
    """L·∫•y l·ªãch s·ª≠ chat TR·ª∞C TI·∫æP t·ª´ MongoDB cho user c·ª• th·ªÉ."""
    print(f"--- DEBUG: Loading history for session '{session_id}' / user '{user_id}' from DB ---")
    return load_session_messages(session_id, user_id)


# ==============================================================================
# SECTION 3: C√ÅC H√ÄM T·∫†O CHAIN (CHAIN FACTORY FUNCTIONS)
# ==============================================================================

# --- PROMPTS (C·∫≠p nh·∫≠t v·ªõi format) ---
ROUTER_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† AI ph√¢n lo·∫°i c√¢u h·ªèi. D·ª±a tr√™n L·ªãch s·ª≠ tr√≤ chuy·ªán v√† C√¢u h·ªèi m·ªõi,
h√£y ph√¢n lo·∫°i c√¢u h·ªèi v√†o M·ªòT trong ba lo·∫°i sau:
1.  `rag_query`: C√¢u h·ªèi y√™u c·∫ßu th√¥ng tin v·ªÅ quy tr√¨nh, th·ªß t·ª•c, ho·∫∑c th√¥ng tin chung.
2.  `history_query`: C√¢u h·ªèi v·ªÅ ch√≠nh cu·ªôc h·ªôi tho·∫°i.
3.  `file_rag_query`: C√¢u h·ªèi li√™n quan ƒë·∫øn t√†i li·ªáu, file (PDF) M√Ä NG∆Ø·ªúI D√ôNG V·ª™A T·∫¢I L√äN.
Ch·ªâ tr·∫£ l·ªùi b·∫±ng M·ªòT t·ª´ duy nh·∫•t: `rag_query` ho·∫∑c `history_query` ho·∫∑c `file_rag_query`.
---
[T√¨nh tr·∫°ng file]
{file_status}
---
[L·ªãch s·ª≠ tr√≤ chuy·ªán]
{chat_history}
---
[C√¢u h·ªèi m·ªõi]
{question}
---
Ph√¢n lo·∫°i (ch·ªâ 1 t·ª´):
""")

HISTORY_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† tr·ª£ l√Ω AI t·∫°i CUSC.
Ch·ªâ d·ª±a v√†o L·ªäCH S·ª¨ TR√í CHUY·ªÜN ƒë∆∞·ª£c cung c·∫•p, h√£y tr·∫£ l·ªùi C√ÇU H·ªéI c·ªßa ng∆∞·ªùi d√πng.
Kh√¥ng ƒë∆∞·ª£c b·ªãa ƒë·∫∑t th√¥ng tin.
---
L·ªãch s·ª≠ tr√≤ chuy·ªán:
{chat_history}
---
C√¢u h·ªèi: {question}
---
C√¢u tr·∫£ l·ªùi:
""")

VISION_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† tr·ª£ l√Ω AI. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi C√ÇU H·ªéI c·ªßa ng∆∞·ªùi d√πng.
ƒê·ªÉ tr·∫£ l·ªùi, b·∫°n ph·∫£i s·ª≠ d·ª•ng T·∫§T C·∫¢ c√°c th√¥ng tin sau:
1. H√åNH ·∫¢NH ƒë∆∞·ª£c cung c·∫•p.
2. L·ªäCH S·ª¨ TR√í CHUY·ªÜN (ƒë·ªÉ hi·ªÉu b·ªëi c·∫£nh).
H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông t√¨m ki·∫øm t√†i li·ªáu (RAG) n·∫øu c·∫ßn.
H√£y ph√¢n t√≠ch H√åNH ·∫¢NH, k·∫øt h·ª£p th√¥ng tin t√¨m ƒë∆∞·ª£c (n·∫øu c√≥) v√† tr·∫£ l·ªùi C√ÇU H·ªéI.
---
[L·ªãch s·ª≠ tr√≤ chuy·ªán]
{chat_history}
---
[C√¢u h·ªèi]
{question}
---
C√¢u tr·∫£ l·ªùi chi ti·∫øt:
""")

RAG_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† tr·ª£ l√Ω AI t·∫°i CUSC. S·ª≠ d·ª•ng c√¥ng c·ª• t√¨m ki·∫øm file ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ l·∫•y th√¥ng tin li√™n quan t·ª´ t√†i li·ªáu v√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.

L·ªãch s·ª≠ tr√≤ chuy·ªán tr∆∞·ªõc:
{chat_history}

C√¢u h·ªèi hi·ªán t·∫°i: {question}

Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c l·∫•y v√† l·ªãch s·ª≠ tr√≤ chuy·ªán:
""")

FALLBACK_PROMPT_TEMPLATE = PromptTemplate.from_template("""
D·ª±a tr√™n l·ªãch s·ª≠ tr√≤ chuy·ªán v√† c√¢u h·ªèi, h√£y cung c·∫•p c√¢u tr·∫£ l·ªùi h·ªØu √≠ch.

L·ªãch s·ª≠:
{chat_history}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi:
""")


# --- H√ÄM VI·∫æT L·∫†I (create_rag_router_chain) V·ªöI LOGIC M·ªöI ---
def create_rag_router_chain(llm):
    """T·∫°o chain RAG c√≥ b·ªô ƒë·ªãnh tuy·∫øn, s·ª≠ d·ª•ng Google File Search Tool (SDK th√¥)."""
    if llm is None:
        print("L·ªói: Kh√¥ng th·ªÉ t·∫°o RAG chain do thi·∫øu LLM.")
        return None

    def get_history_for_request(session_id: str, user_id: str):
        return get_session_history(session_id, user_id)

    # --- Chain nh√°nh c∆° s·ªü (History Path, Fallback) ---
    history_chain = HISTORY_PROMPT_TEMPLATE | llm | StrOutputParser()
    base_llm_chain = FALLBACK_PROMPT_TEMPLATE | llm | StrOutputParser()

    # --- Logic Route (M·ªöI) ---
    def route(input_dict, config=None):
        session_id = config["configurable"]["session_id"]
        user_id = config["configurable"]["user_id"]
        question = input_dict["question"]
        chat_history = input_dict["chat_history"]

        # FIXED: Ki·ªÉm tra user ownership c·ªßa session
        if not check_session_belongs_to_user(session_id, user_id):
            return "L·ªói: Session kh√¥ng thu·ªôc v·ªÅ user n√†y."

        # --- 1. DETECT INTENT ---
        file_status = "Kh√¥ng c√≥ t√†i li·ªáu c·ª• th·ªÉ"
        user_file_store_name = get_session_file_store(session_id)
        if user_file_store_name:
            file_status = f"Ng∆∞·ªùi d√πng ƒë√£ t·∫£i l√™n t√†i li·ªáu cho session n√†y (Store: {user_file_store_name})"

        file_keywords = ["file", "t√†i li·ªáu", "t·∫≠p tin", "pdf", "v·ª´a t·∫£i", "ƒë√£ t·∫£i", "upload", "ƒë·ªçc file"]
        is_file_question = any(kw.lower() in question.lower() for kw in file_keywords)

        # Route qua file store n·∫øu c√≥ t·ª´ kh√≥a file V√Ä c√≥ file store
        if is_file_question and user_file_store_name:
            print(f"--- (Router: File Search - Session Store: {user_file_store_name}) ---")
            store_to_use = user_file_store_name
        elif not is_file_question and app_config.CUSC_MAIN_STORE_NAME:
            # C√¢u h·ªèi chung - d√πng main store
            print(f"--- (Router: General RAG - Main Store: {app_config.CUSC_MAIN_STORE_NAME}) ---")
            store_to_use = app_config.CUSC_MAIN_STORE_NAME
        elif is_file_question and not user_file_store_name:
            # User h·ªèi v·ªÅ file nh∆∞ng ch∆∞a upload
            print("--- (Router: User h·ªèi v·ªÅ file nh∆∞ng ch∆∞a upload) ---")
            return "B·∫°n ch∆∞a t·∫£i l√™n t√†i li·ªáu n√†o cho session n√†y. Vui l√≤ng t·∫£i file PDF tr∆∞·ªõc khi h·ªèi."
        else:
            # Kh√¥ng c√≥ store n√†o - tr·∫£ l·ªùi b√¨nh th∆∞·ªùng
            print("--- (Router: Kh√¥ng c√≥ File Store - Tr·∫£ l·ªùi b√¨nh th∆∞·ªùng) ---")
            return base_llm_chain.invoke(input_dict)

        # Raw SDK cho RAG v·ªõi citations (INVOKE NGAY)
        def rag_raw_func(inputs):
            question = inputs["question"]
            chat_history = inputs["chat_history"]
            history_str = format_chat_history(chat_history)
            prompt_text = RAG_PROMPT_TEMPLATE.invoke({
                "chat_history": history_str,
                "question": question
            }).to_string()

            try:
                # FIXED: Ki·ªÉm tra GLOBAL_GENAI_CLIENT kh√¥ng ph·∫£i None
                if GLOBAL_GENAI_CLIENT is None:
                    return "L·ªói: Google AI client ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o."

                response = GLOBAL_GENAI_CLIENT.models.generate_content(
                    model=app_config.TEXT_MODEL_NAME,
                    contents=prompt_text,
                    config=types.GenerateContentConfig(
                        tools=[
                            types.Tool(
                                file_search=types.FileSearch(
                                    file_search_store_names=[store_to_use]
                                )
                            )
                        ]
                    ),
                )
                # FIXED: Ki·ªÉm tra response v√† response.text t·ªìn t·∫°i
                if response and hasattr(response, 'text'):
                    text_response = response.text if response.text else "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."
                else:
                    text_response = "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."

                citations = extract_citations(response)
                return text_response + citations
            except Exception as e:
                return f"L·ªói khi t·∫°o n·ªôi dung: {str(e)}"

        return rag_raw_func(input_dict)

    # --- Chain c∆° s·ªü c√≥ router (Gi·ªØ nguy√™n) ---
    base = (
            {"question": lambda x: x["question"],
             "chat_history": lambda x: x.get("chat_history", [])}
            | RunnableLambda(route)
    )

    # --- B·ªçc b·ªô nh·ªõ (Gi·ªØ nguy√™n) ---
    chain_with_history = RunnableWithMessageHistory(
        base,
        get_history_for_request,
        input_messages_key="question",
        history_messages_key="chat_history",
        history_factory_config=[
            ConfigurableFieldSpec(id="user_id", annotation=str, name="User ID"),
            ConfigurableFieldSpec(id="session_id", annotation=str, name="Session ID"),
        ]
    )
    return chain_with_history


# --- H√ÄM VI·∫æT L·∫†I (create_vision_chain) V·ªöI LOGIC M·ªöI ---
def create_vision_chain(llm):
    """T·∫°o chain Vision RAG, s·ª≠ d·ª•ng Google File Search Tool (SDK th√¥)."""
    if llm is None:
        print("L·ªói: Kh√¥ng th·ªÉ t·∫°o Vision chain do thi·∫øu LLM.")
        return None

    # --- Logic Route (M·ªöI - INVOKE NGAY) ---
    def route_vision(input_dict, config=None):
        session_id = config["configurable"]["session_id"]
        user_id = config["configurable"]["user_id"]

        # FIXED: Ki·ªÉm tra user ownership c·ªßa session
        if not check_session_belongs_to_user(session_id, user_id):
            return "L·ªói: Session kh√¥ng thu·ªôc v·ªÅ user n√†y."

        history = input_dict.get("chat_history", [])
        # FIXED: X·ª≠ l√Ω c·∫£ HumanMessage v√† image_path
        if "image_path" in input_dict:
            # Input t·ª´ CLI v·ªõi image_path
            image_path = input_dict["image_path"]
            question_text = input_dict["question"]

            # Ki·ªÉm tra file ·∫£nh t·ªìn t·∫°i
            if not os.path.exists(image_path):
                return f"L·ªói: Kh√¥ng t√¨m th·∫•y ·∫£nh t·∫°i '{image_path}'"

            image_base64 = image_to_base64(image_path)
            if not image_base64:
                return "L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh."
        else:
            # Input t·ª´ API/chain v·ªõi HumanMessage
            human_message_input = input_dict["question"]

            # Extract question_text v√† image_base64 t·ª´ HumanMessage
            question_text = ""
            image_base64 = None
            image_parts = []

            if hasattr(human_message_input, 'content'):
                content = human_message_input.content
                if isinstance(content, list):
                    for part in content:
                        if isinstance(part, dict):
                            if part.get("type") == "text":
                                question_text = part.get("text", "")
                            elif part.get("type") == "image_url":
                                url = part["image_url"].get("url", "")
                                if url.startswith("data:image/jpeg;base64,"):
                                    image_base64 = url.split(",")[1]
                                image_parts.append(part)
                else:
                    question_text = content
            else:
                question_text = str(human_message_input)

        # 1. CH·ªåN TOOL RAG (∆ØU TI√äN SESSION N·∫æU C√ì)
        store_to_use = None
        user_file_store_name = get_session_file_store(session_id)

        if user_file_store_name:
            print(f"--- (Vision: G·∫Øn Session File Store {user_file_store_name}) ---")
            store_to_use = user_file_store_name
        elif app_config.CUSC_MAIN_STORE_NAME:
            print(f"--- (Vision: G·∫Øn Main File Store {app_config.CUSC_MAIN_STORE_NAME}) ---")
            store_to_use = app_config.CUSC_MAIN_STORE_NAME
        else:
            print("--- (Vision: Kh√¥ng c√≥ File Store) ---")

        if not question_text:
            return "L·ªói: Kh√¥ng c√≥ c√¢u h·ªèi."

        if not image_base64:
            return "L·ªói: Kh√¥ng t√¨m th·∫•y ·∫£nh."

        history_str = format_chat_history(history)
        prompt_text = VISION_PROMPT_TEMPLATE.invoke({
            "question": question_text,
            "chat_history": history_str,
        }).to_string()

        if store_to_use:
            # Raw SDK v·ªõi tool v√† citations
            try:
                # FIXED: Ki·ªÉm tra GLOBAL_GENAI_CLIENT
                if GLOBAL_GENAI_CLIENT is None:
                    return "L·ªói: Google AI client ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o."

                contents = [
                    types.Part(text=prompt_text),
                    types.Part(
                        inline_data=types.Blob(
                            mime_type="image/jpeg",
                            data=base64.b64decode(image_base64)
                        )
                    )
                ]

                tool_config = types.GenerateContentConfig(
                    tools=[
                        types.Tool(
                            file_search=types.FileSearch(
                                file_search_store_names=[store_to_use]
                            )
                        )
                    ]
                )
                response = GLOBAL_GENAI_CLIENT.models.generate_content(
                    model=app_config.VISION_MODEL_NAME,
                    contents=contents,
                    config=tool_config
                )
                # FIXED: Ki·ªÉm tra response
                if response and hasattr(response, 'text'):
                    text_response = response.text if response.text else "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."
                else:
                    text_response = "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."

                citations = extract_citations(response)
                return text_response + citations
            except Exception as e:
                return f"L·ªói khi t·∫°o n·ªôi dung: {str(e)}"
        else:
            # LangChain kh√¥ng tool
            try:
                # T·∫°o HumanMessage v·ªõi c·∫£ text v√† image
                final_content = [
                    {"type": "text", "text": prompt_text},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
                final_hm = HumanMessage(content=final_content)
                response = VISION_LLM.invoke(final_hm)
                return response.content if hasattr(response, 'content') else str(response)
            except Exception as e:
                return f"L·ªói khi t·∫°o n·ªôi dung: {str(e)}"

    # --- C√°c h√†m helper cho b·ªô nh·ªõ ---
    def _format_history_input(input_dict):
        # FIXED: X·ª≠ l√Ω c·∫£ tr∆∞·ªùng h·ª£p c√≥ image_path
        if "image_path" in input_dict:
            question = input_dict["question"]
            img_path = input_dict["image_path"]
            if not os.path.exists(img_path):
                return HumanMessage(content=f"(L·ªói ·∫£nh) {question}")
            image_base64 = image_to_base64(img_path)
            if not image_base64:
                return HumanMessage(content=f"(L·ªói ·∫£nh) {question}")
            image_data = {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
            return HumanMessage(content=[{"type": "text", "text": question}, image_data])
        else:
            # Tr∆∞·ªùng h·ª£p ƒë√£ c√≥ HumanMessage
            return input_dict["question"]

    def get_history_for_request(session_id: str, user_id: str):
        return get_session_history(session_id, user_id)

    # --- Chain c∆° s·ªü ---
    base_vision = RunnableLambda(route_vision)

    # --- B·ªçc b·ªô nh·ªõ ---
    vision_chain_with_history = RunnableWithMessageHistory(
        base_vision,
        get_history_for_request,
        input_messages_key="question",
        input_messages_key_fx=RunnableLambda(_format_history_input),
        history_messages_key="chat_history",
        history_factory_config=[
            ConfigurableFieldSpec(id="user_id", annotation=str, name="User ID"),
            ConfigurableFieldSpec(id="session_id", annotation=str, name="Session ID"),
        ]
    )
    return vision_chain_with_history


# ==============================================================================
# SECTION 4: KH·ªûI T·∫†O CHAIN TO√ÄN C·ª§C (ƒê·ªÇ API S·ª¨ D·ª§NG)
# ==============================================================================

RAG_CHAIN_WITH_HISTORY = create_rag_router_chain(TEXT_LLM)
VISION_CHAIN_WITH_HISTORY = create_vision_chain(VISION_LLM)


# ==============================================================================
# SECTION 5: C√ÅC H√ÄM X·ª¨ L√ù CLI (COMMAND-LINE INTERFACE)
# ==============================================================================

def handle_text_query(query_text, user_id, session_id="default_session"):
    print("--- üîç ƒêang x·ª≠ l√Ω c√¢u h·ªèi vƒÉn b·∫£n b·∫±ng RAG ---")
    chain_to_run = RAG_CHAIN_WITH_HISTORY
    if chain_to_run is None:
        return
    full_response = ""
    config_ = {"configurable": {"session_id": session_id, "user_id": user_id}}
    input_data = {"question": query_text}
    try:
        # S·ª≠ d·ª•ng invoke thay v√¨ stream v√¨ route tr·∫£ v·ªÅ str tr·ª±c ti·∫øp
        response = chain_to_run.invoke(input_data, config=config_)
        full_response = str(response)
        print(full_response)
        print("\n")
        save_session_message(session_id, user_id, query_text, full_response)
    except Exception as e:
        print(f"\nL·ªói khi x·ª≠ l√Ω c√¢u h·ªèi text: {e}")


def handle_multimodal_query(query_text, image_path, user_id, session_id="default_session"):
    print(f"--- üñºÔ∏è X·ª≠ l√Ω c√¢u h·ªèi c√≥ ·∫£nh: {os.path.basename(image_path)} ---")
    chain_to_run = VISION_CHAIN_WITH_HISTORY
    if chain_to_run is None:
        return
    full_response = ""
    input_data = {"question": query_text, "image_path": image_path}
    config_ = {"configurable": {"session_id": session_id, "user_id": user_id}}
    try:
        # S·ª≠ d·ª•ng invoke thay v√¨ stream v√¨ route tr·∫£ v·ªÅ str tr·ª±c ti·∫øp
        response = chain_to_run.invoke(input_data, config=config_)
        full_response = str(response)
        print(full_response)
        print("\n")
        save_session_message(session_id, user_id, query_text, full_response, image_path=image_path)
    except Exception as e:
        print(f"\nL·ªói khi x·ª≠ l√Ω c√¢u h·ªèi ·∫£nh: {e}")


def handle_pdf_upload(pdf_path: str, session_id: str, user_id: str):
    print(f"\n‚è≥ ƒêang x·ª≠ l√Ω file: {pdf_path}...")
    try:
        file_id = save_pdf_to_mongo(pdf_path, session_id, user_id)
        if file_id:
            process_and_vectorize_pdf(pdf_path, session_id, user_id)  # H√†m ƒë√£ refactor
            print("‚úÖ X·ª≠ l√Ω v√† t·∫£i file l√™n Google th√†nh c√¥ng.")
        else:
            print("‚ùå L·ªói khi l∆∞u file v√†o DB.")
    except Exception as ex:
        print(f"‚ùå L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω file PDF: {ex}")


# ==============================================================================
# SECTION 6: H√ÄM MAIN CHO CLI (Gi·ªØ nguy√™n)
# ==============================================================================

def main():
    print("ü§ñ Chatbot CUSC (Google File Search) s·∫µn s√†ng!")
    print("=" * 30)
    print("[1] T·∫°o session m·ªõi")
    print("[2] Ti·∫øp t·ª•c session c≈©")

    user_id = "6910c339c0f7d8f23ecc1cc4"  # User ID v√≠ d·ª•
    choice = input("L·ª±a ch·ªçn c·ªßa b·∫°n (1 ho·∫∑c 2): ").strip()
    if choice == '2':
        print("\nƒêang t·∫£i c√°c session g·∫ßn ƒë√¢y...")
        sessions = list_sessions(limit=10, user_id=user_id)
        if not sessions:
            print("Kh√¥ng t√¨m th·∫•y session n√†o. S·∫Ω t·∫°o session m·ªõi.")
            session_id = str(uuid.uuid4())
        else:
            for i, s in enumerate(sessions):
                print(f"  [{i + 1}] {s['session_id']} ({s['num_messages']} tin nh·∫Øn, c·∫≠p nh·∫≠t: {s['updated_at']})")
            try:
                s_choice = int(input("Ch·ªçn session (nh·∫≠p s·ªë 1, 2,...) ho·∫∑c 0 ƒë·ªÉ t·∫°o m·ªõi: ").strip())
                if 0 < s_choice <= len(sessions):
                    session_id = sessions[s_choice - 1]['session_id']
                else:
                    session_id = str(uuid.uuid4())
            except ValueError:
                session_id = str(uuid.uuid4())
    else:
        session_id = str(uuid.uuid4())
    print(f"\nüÜî Session ID hi·ªán t·∫°i: {session_id}")
    print("   G√µ 'exit' ƒë·ªÉ tho√°t.")
    print("   G√µ 'pdf' ƒë·ªÉ t·∫£i file PDF m·ªõi.\n")
    get_session_history(session_id, user_id)
    while True:
        print("-" * 20)
        user_input = input("üë§ B·∫°n h·ªèi (ho·∫∑c g√µ 'pdf'): ")
        if user_input.lower() == "exit":
            print("T·∫°m bi·ªát!")
            break
        if user_input.lower() == "pdf":
            pdf_path = input("üìÇ Nh·∫≠p ƒë∆∞·ªùng d·∫´n PDF: ").strip()
            if pdf_path and os.path.exists(pdf_path):
                handle_pdf_upload(pdf_path, session_id, user_id)
            else:
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file t·∫°i '{pdf_path}'")
            continue
        query_text = user_input
        image_path = input("üñºÔ∏è Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh (Enter n·∫øu kh√¥ng c√≥): ").strip()
        print("\nüí° Tr·∫£ l·ªùi:")
        if image_path and os.path.exists(image_path):
            handle_multimodal_query(query_text, image_path, user_id, session_id)
        elif image_path:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh t·∫°i '{image_path}'")
        else:
            handle_text_query(query_text, user_id, session_id)


if __name__ == "__main__":
    main()