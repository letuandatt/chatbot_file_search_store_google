import os
import io
import base64
import uuid
import gridfs
import pytz
import hashlib
import google.genai as genai
import google.genai.types as types
from chatbot import config as app_config

from datetime import datetime, timezone
from pymongo import MongoClient, ASCENDING, DESCENDING
from bson.objectid import ObjectId
from PIL import Image

# --- LangChain Imports ---
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables import RunnableLambda, ConfigurableFieldSpec
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate


# ==============================================================================
# SECTION 1: KH·ªûI T·∫†O C√ÅC TH√ÄNH PH·∫¶N TO√ÄN C·ª§C (GLOBAL COMPONENTS)
# ==============================================================================

# --- MONGODB CONNECTION ---
try:
    _mongo_client = MongoClient(app_config.MONGO_URI, serverSelectionTimeoutMS=5000, connectTimeoutMS=5000)
    _mongo_client.admin.command('ping')
    print("MongoDB ping successful.")

    _mongo_db = _mongo_client[app_config.MONGO_DB_NAME]
    DB_COLLECTION = _mongo_db["sessions"]
    FS = gridfs.GridFS(_mongo_db)

    DB_COLLECTION.create_index([("session_id", ASCENDING)], unique=True)
    DB_COLLECTION.create_index([("updated_at", DESCENDING)])
    print(f"Connected successfully to MongoDB and GridFS.")
except Exception as e:
    print(f"Failed to connect to MongoDB: {e}")
    DB_COLLECTION, FS, _mongo_db = None, None, None

# --- GOOGLE AI SDK CLIENT (M·ªöI) ---
try:
    GLOBAL_GENAI_CLIENT = genai.Client()
    print("Google Generative AI SDK client initialized.")
except Exception as e:
    print(f"L·ªói khi c·∫•u h√¨nh Google AI SDK client: {e}")
    GLOBAL_GENAI_CLIENT = None


def get_mongo_collection(collection_name: str = "sessions"):
    """Tr·∫£ v·ªÅ collection 'sessions' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o."""
    if _mongo_client is None or _mongo_db is None:
        print(f"L·ªói: K·∫øt n·ªëi MongoDB ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p")
        return None
    try:
        return _mongo_db[collection_name]
    except Exception as ex:
        print(f"L·ªói khi l·∫•y collection '{collection_name}': {ex}")
        return None


try:
    DB_DOCUMENTS_COLLECTION = get_mongo_collection("documents")
    if DB_DOCUMENTS_COLLECTION is not None:
        DB_DOCUMENTS_COLLECTION.create_index([("session_id", ASCENDING)])
        DB_DOCUMENTS_COLLECTION.create_index([("user_id", ASCENDING)])
        DB_DOCUMENTS_COLLECTION.create_index([("created_at", DESCENDING)])
        print("MongoDB collection 'documents' initialized.")
except Exception as e:
    print(f"Failed to initialize 'documents' collection: {e}")
    DB_DOCUMENTS_COLLECTION = None


def check_session_belongs_to_user(session_id: str, user_id: str) -> bool:
    """Ki·ªÉm tra session c√≥ t·ªìn t·∫°i v√† thu·ªôc v·ªÅ user_id kh√¥ng."""
    coll = get_mongo_collection("sessions")  # L·∫•y collection sessions
    if coll is None:
        return False
    try:
        # ƒê·∫øm s·ªë document kh·ªõp c·∫£ session_id v√† user_id
        return coll.count_documents({"session_id": session_id, "user_id": user_id}, limit=1) > 0
    except Exception as e:
        print(f"L·ªói khi ki·ªÉm tra session ownership: {e}")
        return False


# --- VIETNAM TIMEZONE DEFINITION (Gi·ªØ nguy√™n) ---
try:
    VN_TZ = pytz.timezone("Asia/Ho_Chi_Minh")
    print("VN_TZ initialized successfully.")
except pytz.UnknownTimeZoneError:
    VN_TZ = timezone.utc


# --- LLM MODEL (Gi·ªØ nguy√™n) ---
def initialize_llm(model_name, temperature):
    return ChatGoogleGenerativeAI(
        model=model_name,
        temperature=temperature
    )


try:
    TEXT_LLM = initialize_llm(app_config.TEXT_MODEL_NAME, 0.1)
    VISION_LLM = initialize_llm(app_config.VISION_MODEL_NAME, 0.1)
    print("LLM (LangChain) models initialized successfully.")
except Exception as e:
    print(f"‚ùå Failed to initialize LLMs: {e}")
    TEXT_LLM, VISION_LLM = None, None


# ==============================================================================
# SECTION 2: C√ÅC H√ÄM TI·ªÜN √çCH C·ªêT L√ïI (CORE UTILITY FUNCTIONS)
# ==============================================================================
def format_chat_history(history):
    """Format l·ªãch s·ª≠ chat th√†nh chu·ªói vƒÉn b·∫£n ƒë·ªÉ ƒë∆∞a v√†o prompt."""
    if not history:
        return "No previous messages."
    formatted_parts = []
    for message in history:
        role = getattr(message, 'role', str(type(message).__name__))
        content = getattr(message, 'content', str(message))
        if isinstance(content, list):
            # X·ª≠ l√Ω n·ªôi dung multimodal (ch·ªâ l·∫•y text)
            text_content = ""
            for part in content:
                if isinstance(part, dict) and part.get("type") == "text":
                    text_content = part.get("text", "")
                    break
            content = text_content
        formatted_parts.append(f"{role.upper()}: {content}")
    return "\n\n".join(formatted_parts)


def extract_citations(response):
    """Tr√≠ch xu·∫•t v√† format ngu·ªìn tr√≠ch d·∫´n t·ª´ response metadata, gi·ªëng test_query.py."""
    citations_str = "\n\n--- Ngu·ªìn tr√≠ch d·∫´n ---\n"
    try:
        metadata = response.candidates[0].grounding_metadata
        if not (metadata and metadata.grounding_supports and metadata.grounding_chunks):
            return ""  # Kh√¥ng c√≥ tr√≠ch d·∫´n

        all_chunks = metadata.grounding_chunks
        citations_by_file = {}

        for support in metadata.grounding_supports:
            segment_text = support.segment.text
            for chunk_index in support.grounding_chunk_indices:
                if 0 <= chunk_index < len(all_chunks):
                    chunk = all_chunks[chunk_index]
                    filename = chunk.retrieved_context.title
                    if filename not in citations_by_file:
                        citations_by_file[filename] = set()
                    citations_by_file[filename].add(segment_text)

        if not citations_by_file:
            return ""

        for filename, segments in citations_by_file.items():
            citations_str += f"Ngu·ªìn: {filename}\n"
            citations_str += "-" * 20 + "\n"
            for segment in segments:
                citations_str += f"{segment}\n"
            citations_str += "\n"

        return citations_str
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t citations: {e}")
        return ""


def save_session_message(session_id, user_id, question, answer, image_path=None):
    """L∆∞u c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi v√†o MongoDB (b·∫£n t·ªëi ∆∞u)."""
    coll = get_mongo_collection()
    fs_client = FS
    if coll is None or fs_client is None:
        print("L·ªói: Kh√¥ng th·ªÉ l∆∞u session, DB ho·∫∑c GridFS ch∆∞a k·∫øt n·ªëi.")
        return

    now = datetime.now(VN_TZ).isoformat()

    image_gridfs_id = None

    if image_path and os.path.exists(image_path):
        try:
            with open(image_path, "rb") as i_f:
                image_gridfs_id = fs_client.put(
                    i_f,
                    filename=os.path.basename(image_path),
                    metadata={
                        "session_id": session_id,
                        "created_at": now,
                        "updated_at": now
                    }
                )
        except Exception as ex:
            print(f"L·ªói khi l∆∞u ·∫£nh v√†o GridFS: {ex}")

    new_messages = [
        {
            "role": "user",
            "content": question,
            "image_gridfs_id": str(image_gridfs_id) if image_gridfs_id else None,
            "timestamp": now
        },
        {
            "role": "assistant",
            "content": answer,
            "timestamp": datetime.now(VN_TZ).isoformat()
        }
    ]

    coll.update_one(
        {"session_id": session_id, "user_id": user_id},
        {
            "$push": {"messages": {"$each": new_messages}},
            "$set": {"updated_at": datetime.now(VN_TZ).isoformat()},
            "$setOnInsert": {  # <-- Ch·ªâ set c√°c tr∆∞·ªùng n√†y khi T·∫†O M·ªöI
                "created_at": now
            }
        },
        upsert=True  # <-- T·ª± ƒë·ªông t·∫°o n·∫øu ch∆∞a c√≥
    )


def load_session_messages(session_id: str, user_id: str, max_history_message: int = 50):
    """Load l·ªãch s·ª≠ h·ªôi tho·∫°i t·ª´ MongoDB."""
    coll = get_mongo_collection("sessions")
    fs_client = FS
    if coll is None or fs_client is None:
        return InMemoryChatMessageHistory()

    history = InMemoryChatMessageHistory()

    try:
        session_doc = coll.find_one(
            {"session_id": session_id, "user_id": user_id},
            projection={"messages": {"$slice": -max_history_message}}
        )

        if not session_doc:
            print(f"DEBUG: Session {session_id} not found or doesn't belong to user {user_id}")
            return history

        for msg in session_doc.get("messages", []):
            if msg["role"] == "user":
                image_gridfs_id_str = msg.get("image_gridfs_id")
                content_list = [{"type": "text", "text": msg["content"]}]
                if image_gridfs_id_str:
                    try:
                        image_id = ObjectId(image_gridfs_id_str)
                        image_data = fs_client.get(image_id)  # D√πng fs_client
                        image_base64 = base64.b64encode(image_data.read()).decode("utf-8")
                        content_list.append(
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}} )
                    except Exception as ex:
                        print(f"L·ªói khi t·∫£i ·∫£nh t·ª´ GridFS (ID: {image_gridfs_id_str}): {ex}")
                history.add_message(HumanMessage(content=content_list))
            elif msg["role"] == "assistant":
                history.add_message(AIMessage(content=msg["content"]))
            else:
                print(f"‚ö†Ô∏è Unknown role: {msg['role']}")
    except Exception as e:
        print(f"L·ªói khi t·∫£i session ({session_id}) t·ª´ MongoDB: {e}")
        # Tr·∫£ v·ªÅ history r·ªóng ƒë·ªÉ tr√°nh crash
        return InMemoryChatMessageHistory()

    return history


def list_sessions(user_id: str, limit=50):
    """Li·ªát k√™ c√°c session (ƒë√£ t·ªëi ∆∞u) m√† kh√¥ng t·∫£i messages."""
    coll = get_mongo_collection("sessions")
    if coll is None:
        return []

    pipeline = [
        {
            "$match": {"user_id": user_id}
        },
        {
            "$project": {  # Ch·ªâ l·∫•y c√°c tr∆∞·ªùng n√†y
                "_id": 0,
                "session_id": 1,
                "session_name": 1,
                "updated_at": 1,
                "created_at": 1,
                "num_messages": {"$size": "$messages"}  # Y√™u c·∫ßu DB ƒë·∫øm
            }
        },
        {
            "$sort": {"updated_at": DESCENDING}
        },
        {
            "$limit": limit  # Ch·ªâ l·∫•y 50 session g·∫ßn nh·∫•t
        }
    ]

    try:
        sessions = list(coll.aggregate(pipeline))
        return sessions
    except Exception as e:
        print(f"L·ªói khi list sessions: {e}")
        return []

# --- (C√°c h√†m qu·∫£n l√Ω file gi·ªØ nguy√™n, ch√∫ng ƒê√É ƒê√öNG) ---
def get_session_file_store(session_id: str) -> str | None:
    # (Gi·ªØ nguy√™n)
    coll = DB_DOCUMENTS_COLLECTION
    if coll is None:
        return None
    try:
        doc_record = coll.find_one(
            {"session_id": session_id, "status": "processed"},
            projection={"file_store_name": 1}
        )
        return doc_record.get("file_store_name") if doc_record else None
    except Exception:
        return None


def compute_file_hash(file_path: str) -> str:
    """T·∫°o hash MD5 cho file ƒë·ªÉ tr√°nh tr√πng."""
    with open(file_path, "rb") as f:
        file_data = f.read()
    return hashlib.md5(file_data).hexdigest()


def save_pdf_to_mongo(file_path: str, session_id: str, user_id: str) -> str | None:
    fs_client = FS
    coll = DB_DOCUMENTS_COLLECTION
    if fs_client is None or coll is None:
        print("L·ªói: Kh√¥ng th·ªÉ l∆∞u file, DB ho·∫∑c GridFS ch∆∞a k·∫øt n·ªëi.")
        return None

    now = datetime.now(VN_TZ).isoformat()
    file_name = os.path.basename(file_path)
    file_hash = compute_file_hash(file_path)  # ‚úÖ th√™m d√≤ng n√†y

    try:
        with open(file_path, "rb") as f:
            file_id = fs_client.put(
                f,
                filename=file_name,
                metadata={
                    "session_id": session_id,
                    "user_id": user_id,
                    "file_hash": file_hash,
                    "created_at": now
                }
            )

        doc_record = {
            "session_id": session_id,
            "user_id": user_id,
            "filename": file_name,
            "gridfs_id": str(file_id),
            "file_hash": file_hash,  # ‚úÖ th√™m v√†o ƒë√¢y
            "created_at": now,
            "status": "uploaded"
        }
        coll.insert_one(doc_record)
        print(f"ƒê√£ l∆∞u file '{file_name}' v√†o GridFS (ID: {file_id}) v√† collection 'documents'.")
        return str(file_id)
    except Exception as e:
        print(f"L·ªói khi l∆∞u file PDF v√†o MongoDB: {e}")
        return None


def process_and_vectorize_pdf(file_path: str, session_id: str, user_id: str):
    """

    :param file_path:
    :param session_id:
    :param user_id:
    :return:
    """
    if DB_DOCUMENTS_COLLECTION is None or GLOBAL_GENAI_CLIENT is None:
        return

    client = GLOBAL_GENAI_CLIENT
    file_name = os.path.basename(file_path)
    print(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω v√† t·∫£i file l√™n Google: {file_name}")
    try:
        print(f"ƒêang t·∫°o File Store m·ªõi cho session {session_id}...")
        file_store = client.file_search_stores.create(
            config={'display_name': f"Session Store - {session_id} - {file_name}"}
        )
        store_name = file_store.name
        print(f"T·∫°o th√†nh c√¥ng File Store: {store_name}")

        print(f"ƒêang t·∫£i file {file_name} l√™n store...")
        client.file_search_stores.upload_to_file_search_store(
            file=file_path,
            file_search_store_name=store_name,
            config={'display_name': file_name}
        )
        print("T·∫£i file l√™n th√†nh c√¥ng.")

        DB_DOCUMENTS_COLLECTION.update_one(
            {"session_id": session_id, "filename": file_name, "user_id": user_id},
            {"$set": {"status": "processed", "file_store_name": store_name}}
        )
        print(f"ƒê√£ c·∫≠p nh·∫≠t MongoDB, li√™n k·∫øt session v·ªõi store: {store_name}")
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω file v·ªõi Google File Search: {e}")
        DB_DOCUMENTS_COLLECTION.update_one(
            {"session_id": session_id, "filename": file_name, "user_id": user_id},
            {"$set": {"status": "error_processing"}}
        )


def delete_session_and_associated_files(session_id: str, user_id: str) -> dict:
    """

    :param session_id:
    :param user_id:
    :return:
    """
    sessions_coll = get_mongo_collection("sessions")
    docs_coll = DB_DOCUMENTS_COLLECTION
    fs_client = FS
    client = GLOBAL_GENAI_CLIENT
    if sessions_coll is None or fs_client is None or client is None or docs_coll is None:
        raise Exception("M·ªôt ho·∫∑c nhi·ªÅu th√†nh ph·∫ßn DB (Mongo, GridFS, client) ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")

    deleted_counts = {
        "sessions": 0,
        "document_records": 0,
        "gridfs_files": 0,
        "file_stores": 0
    }

    gridfs_ids_to_delete, file_store_names_to_delete = [], set()

    try:
        session_doc = sessions_coll.find_one({"session_id": session_id, "user_id": user_id})
        if session_doc:
            for msg in session_doc.get("messages", []):
                if msg.get("image_gridfs_id"):
                    try:
                        gridfs_ids_to_delete.append(ObjectId(msg["image_gridfs_id"]))
                    except Exception:
                        pass
        doc_records = list(docs_coll.find({"session_id": session_id, "user_id": user_id}))
        for doc in doc_records:
            if doc.get("gridfs_id"):
                try:
                    gridfs_ids_to_delete.append(ObjectId(doc["gridfs_id"]))
                except Exception:
                    pass
            if doc.get("file_store_name"):
                file_store_names_to_delete.add(doc["file_store_name"])
    except Exception as e:
        print(f"L·ªói khi thu th·∫≠p ID: {e}")

    for file_id in set(gridfs_ids_to_delete):
        try:
            fs_client.delete(file_id); deleted_counts["gridfs_files"] += 1
        except Exception:
            pass

    deleted_counts["sessions"] = sessions_coll.delete_one({"session_id": session_id, "user_id": user_id}).deleted_count
    deleted_counts["document_records"] = docs_coll.delete_many({"session_id": session_id, "user_id": user_id}).deleted_count

    for store_name in file_store_names_to_delete:
        try:
            print(f"ƒêang x√≥a File Store: {store_name}...")
            client.file_search_stores.delete(name=store_name)
            deleted_counts["file_stores"] += 1
            print(f"ƒê√£ x√≥a {store_name}.")
        except Exception as e:
            print(f"L·ªói khi x√≥a File Store {store_name}: {e}")
    return deleted_counts


def image_to_base64(image_path, max_size_px=1024, jpeg_quality=85):
    """Chuy·ªÉn file ·∫£nh sang chu·ªói base64, ƒë·ªìng th·ªùi
    resize v√† n√©n ·∫£nh ƒë·ªÉ t·ªëi ∆∞u chi ph√≠ v√† t·ªëc ƒë·ªô.
    """
    try:
        with Image.open(image_path) as img:
            img.thumbnail((max_size_px, max_size_px))

            if img.mode != 'RGB':
                img = img.convert('RGB')

            buffered = io.BytesIO()
            img.save(
                buffered,
                format="JPEG",
                quality=jpeg_quality,
                optimize=True
            )
            return base64.b64encode(buffered.getvalue()).decode("utf-8")
    except Exception as e:
        print(f"L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
        return None


# --- MEMORY MANAGEMENT ---
def get_session_history(session_id: str, user_id: str):
    """L·∫•y l·ªãch s·ª≠ chat TR·ª∞C TI·∫æP t·ª´ MongoDB cho user c·ª• th·ªÉ."""
    print(f"--- DEBUG: Loading history for session '{session_id}' / user '{user_id}' from DB ---")
    return load_session_messages(session_id, user_id)


# ==============================================================================
# SECTION 3: C√ÅC H√ÄM T·∫†O CHAIN (CHAIN FACTORY FUNCTIONS)
# ==============================================================================

# --- PROMPTS (C·∫≠p nh·∫≠t v·ªõi format) ---
ROUTER_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† AI ph√¢n lo·∫°i c√¢u h·ªèi. D·ª±a tr√™n L·ªãch s·ª≠ tr√≤ chuy·ªán v√† C√¢u h·ªèi m·ªõi,
h√£y ph√¢n lo·∫°i c√¢u h·ªèi v√†o M·ªòT trong ba lo·∫°i sau:
1.  `rag_query`: C√¢u h·ªèi y√™u c·∫ßu th√¥ng tin v·ªÅ quy tr√¨nh, th·ªß t·ª•c, ho·∫∑c th√¥ng tin chung.
2.  `history_query`: C√¢u h·ªèi v·ªÅ ch√≠nh cu·ªôc h·ªôi tho·∫°i.
3.  `file_rag_query`: C√¢u h·ªèi li√™n quan ƒë·∫øn t√†i li·ªáu, file (PDF) M√Ä NG∆Ø·ªúI D√ôNG V·ª™A T·∫¢I L√äN.
Ch·ªâ tr·∫£ l·ªùi b·∫±ng M·ªòT t·ª´ duy nh·∫•t: `rag_query` ho·∫∑c `history_query` ho·∫∑c `file_rag_query`.
---
[T√¨nh tr·∫°ng file]
{file_status}
---
[L·ªãch s·ª≠ tr√≤ chuy·ªán]
{chat_history}
---
[C√¢u h·ªèi m·ªõi]
{question}
---
Ph√¢n lo·∫°i (ch·ªâ 1 t·ª´):
""")

HISTORY_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† tr·ª£ l√Ω AI t·∫°i CUSC.
Ch·ªâ d·ª±a v√†o L·ªäCH S·ª¨ TR√í CHUY·ªÜN ƒë∆∞·ª£c cung c·∫•p, h√£y tr·∫£ l·ªùi C√ÇU H·ªéI c·ªßa ng∆∞·ªùi d√πng.
Kh√¥ng ƒë∆∞·ª£c b·ªãa ƒë·∫∑t th√¥ng tin.
---
L·ªãch s·ª≠ tr√≤ chuy·ªán:
{chat_history}
---
C√¢u h·ªèi: {question}
---
C√¢u tr·∫£ l·ªùi:
""")

VISION_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† tr·ª£ l√Ω AI. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi C√ÇU H·ªéI c·ªßa ng∆∞·ªùi d√πng.
ƒê·ªÉ tr·∫£ l·ªùi, b·∫°n ph·∫£i s·ª≠ d·ª•ng T·∫§T C·∫¢ c√°c th√¥ng tin sau:
1. H√åNH ·∫¢NH ƒë∆∞·ª£c cung c·∫•p.
2. L·ªäCH S·ª¨ TR√í CHUY·ªÜN (ƒë·ªÉ hi·ªÉu b·ªëi c·∫£nh).
H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông t√¨m ki·∫øm t√†i li·ªáu (RAG) n·∫øu c·∫ßn.
H√£y ph√¢n t√≠ch H√åNH ·∫¢NH, k·∫øt h·ª£p th√¥ng tin t√¨m ƒë∆∞·ª£c (n·∫øu c√≥) v√† tr·∫£ l·ªùi C√ÇU H·ªéI.
---
[L·ªãch s·ª≠ tr√≤ chuy·ªán]
{chat_history}
---
[C√¢u h·ªèi]
{question}
---
C√¢u tr·∫£ l·ªùi chi ti·∫øt:
""")

RAG_PROMPT_TEMPLATE = PromptTemplate.from_template("""
B·∫°n l√† tr·ª£ l√Ω AI t·∫°i CUSC. S·ª≠ d·ª•ng c√¥ng c·ª• t√¨m ki·∫øm file ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ l·∫•y th√¥ng tin li√™n quan t·ª´ t√†i li·ªáu v√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.

L·ªãch s·ª≠ tr√≤ chuy·ªán tr∆∞·ªõc:
{chat_history}

C√¢u h·ªèi hi·ªán t·∫°i: {question}

Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c l·∫•y v√† l·ªãch s·ª≠ tr√≤ chuy·ªán:
""")

FALLBACK_PROMPT_TEMPLATE = PromptTemplate.from_template("""
D·ª±a tr√™n l·ªãch s·ª≠ tr√≤ chuy·ªán v√† c√¢u h·ªèi, h√£y cung c·∫•p c√¢u tr·∫£ l·ªùi h·ªØu √≠ch.

L·ªãch s·ª≠:
{chat_history}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi:
""")


# --- H√ÄM VI·∫æT L·∫†I (create_rag_router_chain) V·ªöI LOGIC M·ªöI ---
def create_rag_router_chain(llm):
    """T·∫°o chain RAG c√≥ b·ªô ƒë·ªãnh tuy·∫øn, s·ª≠ d·ª•ng Google File Search Tool (SDK th√¥)."""
    if llm is None:
        print("L·ªói: Kh√¥ng th·ªÉ t·∫°o RAG chain do thi·∫øu LLM.")
        return None

    def get_history_for_request(session_id: str, user_id: str):
        return get_session_history(session_id, user_id)

    # --- Router chain v·ªõi format history ---
    router_chain = (
        {
            "file_status": lambda x: x["file_status"],
            "chat_history": lambda x: format_chat_history(x.get("chat_history", [])),
            "question": lambda x: x["question"]
        }
        | ROUTER_PROMPT_TEMPLATE
        | llm
        | StrOutputParser()
    )

    # --- History chain v·ªõi format ---
    history_chain = (
        {
            "question": lambda x: x["question"],
            "chat_history": lambda x: format_chat_history(x.get("chat_history", []))
        }
        | HISTORY_PROMPT_TEMPLATE
        | llm
        | StrOutputParser()
    )

    # --- Fallback chain v·ªõi format ---
    base_llm_chain = (
        {
            "question": lambda x: x["question"],
            "chat_history": lambda x: format_chat_history(x.get("chat_history", []))
        }
        | FALLBACK_PROMPT_TEMPLATE
        | llm
        | StrOutputParser()
    )

    # --- Logic Route (ƒê√É S·ª¨A ƒê·ªÇ D√ôN SDK TH√î V√Ä INVOKE NGAY) ---
    def route(input_dict, config=None):
        session_id = config["configurable"]["session_id"]

        # 1. Ki·ªÉm tra t√¨nh tr·∫°ng file
        user_file_store_name = get_session_file_store(session_id)
        file_status = "Ng∆∞·ªùi d√πng ƒë√£ t·∫£i l√™n 1 file." if user_file_store_name else "Ng∆∞·ªùi d√πng CH∆ØA t·∫£i l√™n file n√†o."

        # 2. Ch·∫°y router
        try:
            classification = router_chain.invoke({
                "chat_history": input_dict.get("chat_history", []),
                "question": input_dict["question"],
                "file_status": file_status
            }, config)
        except Exception as e:
            classification = "rag_query"

        # 3. Tr·∫£ v·ªÅ chain t∆∞∆°ng ·ª©ng (INVOKE NGAY)
        if "history_query" in classification:
            print("--- (Router: L·ªãch s·ª≠) ---")
            return history_chain.invoke(input_dict)

        # 4. X√°c ƒë·ªãnh store_name ƒë·ªÉ s·ª≠ d·ª•ng (∆ØU TI√äN SESSION N·∫æU C√ì)
        store_to_use = None
        if user_file_store_name:
            print(f"--- (Router: File Search - Session Store: {user_file_store_name}) ---")
            store_to_use = user_file_store_name
        elif app_config.CUSC_MAIN_STORE_NAME:
            print(f"--- (Router: File Search - Main Store: {app_config.CUSC_MAIN_STORE_NAME}) ---")
            store_to_use = app_config.CUSC_MAIN_STORE_NAME

        if not store_to_use:
            print("--- (Router: Kh√¥ng c√≥ File Store - Tr·∫£ l·ªùi b√¨nh th∆∞·ªùng) ---")
            return base_llm_chain.invoke(input_dict)

        # Raw SDK cho RAG v·ªõi citations (INVOKE NGAY)
        def rag_raw_func(inputs):
            question = inputs["question"]
            chat_history = inputs["chat_history"]
            history_str = format_chat_history(chat_history)
            prompt_text = RAG_PROMPT_TEMPLATE.invoke({
                "chat_history": history_str,
                "question": question
            }).to_string()

            try:
                response = GLOBAL_GENAI_CLIENT.models.generate_content(
                    model=app_config.TEXT_MODEL_NAME,
                    contents=prompt_text,
                    config=types.GenerateContentConfig(
                        tools=[
                            types.Tool(
                                file_search=types.FileSearch(
                                    file_search_store_names=[store_to_use]
                                )
                            )
                        ]
                    ),
                )
                text_response = response.text
                citations = extract_citations(response)
                return text_response + citations
            except Exception as e:
                return f"L·ªói khi t·∫°o n·ªôi dung: {str(e)}"

        return rag_raw_func(input_dict)

    # --- Chain c∆° s·ªü c√≥ router (Gi·ªØ nguy√™n) ---
    base = (
        {"question": lambda x: x["question"],
         "chat_history": lambda x: x.get("chat_history", [])}
        | RunnableLambda(route)
    )

    # --- B·ªçc b·ªô nh·ªõ (Gi·ªØ nguy√™n) ---
    chain_with_history = RunnableWithMessageHistory(
        base,
        get_history_for_request,
        input_messages_key="question",
        history_messages_key="chat_history",
        history_factory_config=[
            ConfigurableFieldSpec(id="user_id", annotation=str, name="User ID"),
            ConfigurableFieldSpec(id="session_id", annotation=str, name="Session ID"),
        ]
    )
    return chain_with_history


# --- H√ÄM VI·∫æT L·∫†I (create_vision_chain) V·ªöI LOGIC M·ªöI ---
def create_vision_chain(llm):
    """T·∫°o chain Vision RAG, s·ª≠ d·ª•ng Google File Search Tool (SDK th√¥)."""
    if llm is None:
        print("L·ªói: Kh√¥ng th·ªÉ t·∫°o Vision chain do thi·∫øu LLM.")
        return None

    # --- Logic Route (M·ªöI - INVOKE NGAY) ---
    def route_vision(input_dict, config=None):
        session_id = config["configurable"]["session_id"]

        history = input_dict.get("chat_history", [])
        human_message_input = input_dict["question"]

        # 1. CH·ªåN TOOL RAG (∆ØU TI√äN SESSION N·∫æU C√ì)
        store_to_use = None
        user_file_store_name = get_session_file_store(session_id)

        if user_file_store_name:
            print(f"--- (Vision: G·∫Øn Session File Store {user_file_store_name}) ---")
            store_to_use = user_file_store_name
        elif app_config.CUSC_MAIN_STORE_NAME:
            print(f"--- (Vision: G·∫Øn Main File Store {app_config.CUSC_MAIN_STORE_NAME}) ---")
            store_to_use = app_config.CUSC_MAIN_STORE_NAME
        else:
            print("--- (Vision: Kh√¥ng c√≥ File Store) ---")

        # 2. Extract question_text v√† image_base64 (SAFE CHECK)
        question_text = ""
        image_base64 = None
        image_parts = []
        if hasattr(human_message_input, 'content'):
            content = human_message_input.content
            if isinstance(content, list):
                for part in content:
                    if isinstance(part, dict):
                        if part.get("type") == "text":
                            question_text = part.get("text", "")
                        elif part.get("type") == "image_url":
                            url = part["image_url"].get("url", "")
                            if url.startswith("data:image/jpeg;base64,"):
                                image_base64 = url.split(",")[1]
                            image_parts.append(part)  # Gi·ªØ nguy√™n cho langchain
            else:
                question_text = content
        else:
            # Fallback n·∫øu l√† str
            question_text = str(human_message_input)
            image_base64 = None

        if not question_text:
            return "L·ªói: Kh√¥ng c√≥ c√¢u h·ªèi."

        history_str = format_chat_history(history)
        prompt_text = VISION_PROMPT_TEMPLATE.invoke({
            "question": question_text,
            "chat_history": history_str,
        }).to_string()

        if store_to_use:
            # Raw SDK v·ªõi tool v√† citations (INVOKE NGAY)
            def raw_vision_func(inputs):
                # Re-extract v√¨ inputs gi·ªëng input_dict (SAFE CHECK)
                hm_input = inputs["question"]
                img_b64 = None
                q_text = ""
                if hasattr(hm_input, 'content'):
                    content = hm_input.content
                    if isinstance(content, list):
                        for part in content:
                            if isinstance(part, dict):
                                if part.get("type") == "text":
                                    q_text = part.get("text", "")
                                elif part.get("type") == "image_url":
                                    url = part["image_url"].get("url", "")
                                    if url.startswith("data:image/jpeg;base64,"):
                                        img_b64 = url.split(",")[1]
                                    break
                    else:
                        q_text = content
                else:
                    # Fallback n·∫øu str
                    q_text = str(hm_input)
                    img_b64 = None

                if not img_b64:
                    return "L·ªói: Kh√¥ng t√¨m th·∫•y ·∫£nh."

                hist_str = format_chat_history(inputs["chat_history"])

                p_text = VISION_PROMPT_TEMPLATE.invoke({
                    "question": q_text,
                    "chat_history": hist_str,
                }).to_string()

                contents = [
                    types.Part(text=p_text),
                    types.Part(
                        inline_data=types.Blob(
                            mime_type="image/jpeg",
                            data=base64.b64decode(img_b64)
                        )
                    )
                ]

                try:
                    tool_config = types.GenerateContentConfig(
                        tools=[
                            types.Tool(
                                file_search=types.FileSearch(
                                    file_search_store_names=[store_to_use]
                                )
                            )
                        ]
                    )
                    response = GLOBAL_GENAI_CLIENT.models.generate_content(
                        model=app_config.VISION_MODEL_NAME,
                        contents=contents,
                        config=tool_config
                    )
                    text_response = response.text
                    citations = extract_citations(response)
                    return text_response + citations
                except Exception as e:
                    return f"L·ªói khi t·∫°o n·ªôi dung: {str(e)}"

            return raw_vision_func(input_dict)
        else:
            # LangChain kh√¥ng tool (INVOKE NGAY)
            def langchain_vision_func(inputs):
                hm_input = inputs["question"]
                # Extract (SAFE CHECK)
                q_text = ""
                img_parts = []
                if hasattr(hm_input, 'content'):
                    content = hm_input.content
                    if isinstance(content, list):
                        for part in content:
                            if isinstance(part, dict):
                                if part.get("type") == "text":
                                    q_text = part.get("text", "")
                                elif part.get("type") == "image_url":
                                    img_parts.append(part)
                    else:
                        q_text = content
                else:
                    q_text = str(hm_input)

                hist_str = format_chat_history(inputs["chat_history"])
                p_text = VISION_PROMPT_TEMPLATE.invoke({
                    "question": q_text,
                    "chat_history": hist_str,
                }).to_string()

                final_content = [{"type": "text", "text": p_text}] + img_parts
                final_hm = HumanMessage(content=final_content)

                try:
                    response = VISION_LLM.invoke(final_hm)
                    return response.content
                except Exception as e:
                    return f"L·ªói khi t·∫°o n·ªôi dung: {str(e)}"

            return langchain_vision_func(input_dict)

    # --- C√°c h√†m helper cho b·ªô nh·ªõ (Gi·ªØ nguy√™n) ---
    def _format_history_input(input_dict):
        question = input_dict["question"]
        img_path = input_dict["image_path"]
        image_base64 = image_to_base64(img_path)
        if not image_base64: return HumanMessage(content=f"(L·ªói ·∫£nh) {question}")
        image_data = {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
        return HumanMessage(content=[{"type": "text", "text": question}, image_data])

    def get_history_for_request(session_id: str, user_id: str):
        return get_session_history(session_id, user_id)

    # --- Chain c∆° s·ªü (M·ªöI) ---
    base_vision = RunnableLambda(route_vision)

    # --- B·ªçc b·ªô nh·ªõ (Gi·ªØ nguy√™n) ---
    vision_chain_with_history = RunnableWithMessageHistory(
        base_vision,
        get_history_for_request,
        input_messages_key="question",
        input_messages_key_fx=RunnableLambda(_format_history_input),
        history_messages_key="chat_history",
        history_factory_config=[
            ConfigurableFieldSpec(id="user_id", annotation=str, name="User ID"),
            ConfigurableFieldSpec(id="session_id", annotation=str, name="Session ID"),
        ]
    )
    return vision_chain_with_history


# ==============================================================================
# SECTION 4: KH·ªûI T·∫†O CHAIN TO√ÄN C·ª§C (ƒê·ªÇ API S·ª¨ D·ª§NG)
# ==============================================================================

RAG_CHAIN_WITH_HISTORY = create_rag_router_chain(TEXT_LLM)
VISION_CHAIN_WITH_HISTORY = create_vision_chain(VISION_LLM)


# ==============================================================================
# SECTION 5: C√ÅC H√ÄM X·ª¨ L√ù CLI (COMMAND-LINE INTERFACE)
# ==============================================================================

# (C√°c h√†m n√†y gi·ªØ nguy√™n, ch√∫ng kh√¥ng c·∫ßn thay ƒë·ªïi)
def handle_text_query(query_text, user_id, session_id="default_session"):
    print("--- üîç ƒêang x·ª≠ l√Ω c√¢u h·ªèi vƒÉn b·∫£n b·∫±ng RAG ---")
    chain_to_run = RAG_CHAIN_WITH_HISTORY
    if chain_to_run is None:
        return
    full_response = ""
    config_ = {"configurable": {"session_id": session_id, "user_id": user_id}}
    input_data = {"question": query_text}
    try:
        # S·ª≠ d·ª•ng invoke thay v√¨ stream v√¨ route tr·∫£ v·ªÅ str tr·ª±c ti·∫øp
        response = chain_to_run.invoke(input_data, config=config_)
        full_response = str(response)
        print(full_response)
        print("\n")
        save_session_message(session_id, user_id, query_text, full_response)
    except Exception as e:
        print(f"\nL·ªói khi x·ª≠ l√Ω c√¢u h·ªèi text: {e}")


def handle_multimodal_query(query_text, image_path, user_id, session_id="default_session"):
    print(f"--- üñºÔ∏è X·ª≠ l√Ω c√¢u h·ªèi c√≥ ·∫£nh: {os.path.basename(image_path)} ---")
    chain_to_run = VISION_CHAIN_WITH_HISTORY
    if chain_to_run is None:
        return
    full_response = ""
    input_data = {"question": query_text, "image_path": image_path}
    config_ = {"configurable": {"session_id": session_id, "user_id": user_id}}
    try:
        # S·ª≠ d·ª•ng invoke thay v√¨ stream v√¨ route tr·∫£ v·ªÅ str tr·ª±c ti·∫øp
        response = chain_to_run.invoke(input_data, config=config_)
        full_response = str(response)
        print(full_response)
        print("\n")
        save_session_message(session_id, user_id, query_text, full_response, image_path=image_path)
    except Exception as e:
        print(f"\nL·ªói khi x·ª≠ l√Ω c√¢u h·ªèi ·∫£nh: {e}")


def handle_pdf_upload(pdf_path: str, session_id: str, user_id: str):
    print(f"\n‚è≥ ƒêang x·ª≠ l√Ω file: {pdf_path}...")
    try:
        file_id = save_pdf_to_mongo(pdf_path, session_id, user_id)
        if file_id:
            process_and_vectorize_pdf(pdf_path, session_id, user_id)  # H√†m ƒë√£ refactor
            print("‚úÖ X·ª≠ l√Ω v√† t·∫£i file l√™n Google th√†nh c√¥ng.")
        else:
            print("‚ùå L·ªói khi l∆∞u file v√†o DB.")
    except Exception as ex:
        print(f"‚ùå L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω file PDF: {ex}")


# ==============================================================================
# SECTION 6: H√ÄM MAIN CHO CLI (Gi·ªØ nguy√™n)
# ==============================================================================

def main():
    print("ü§ñ Chatbot CUSC (Google File Search) s·∫µn s√†ng!")
    print("=" * 30)
    print("[1] T·∫°o session m·ªõi")
    print("[2] Ti·∫øp t·ª•c session c≈©")

    user_id = "6910c339c0f7d8f23ecc1cc4"  # User ID v√≠ d·ª•
    choice = input("L·ª±a ch·ªçn c·ªßa b·∫°n (1 ho·∫∑c 2): ").strip()
    if choice == '2':
        print("\nƒêang t·∫£i c√°c session g·∫ßn ƒë√¢y...")
        sessions = list_sessions(limit=10, user_id=user_id)
        if not sessions:
            print("Kh√¥ng t√¨m th·∫•y session n√†o. S·∫Ω t·∫°o session m·ªõi.")
            session_id = str(uuid.uuid4())
        else:
            for i, s in enumerate(sessions):
                print(f"  [{i + 1}] {s['session_id']} ({s['num_messages']} tin nh·∫Øn, c·∫≠p nh·∫≠t: {s['updated_at']})")
            try:
                s_choice = int(input("Ch·ªçn session (nh·∫≠p s·ªë 1, 2,...) ho·∫∑c 0 ƒë·ªÉ t·∫°o m·ªõi: ").strip())
                if 0 < s_choice <= len(sessions):
                    session_id = sessions[s_choice - 1]['session_id']
                else:
                    session_id = str(uuid.uuid4())
            except ValueError:
                session_id = str(uuid.uuid4())
    else:
        session_id = str(uuid.uuid4())
    print(f"\nüÜî Session ID hi·ªán t·∫°i: {session_id}")
    print("   G√µ 'exit' ƒë·ªÉ tho√°t.")
    print("   G√µ 'pdf' ƒë·ªÉ t·∫£i file PDF m·ªõi.\n")
    get_session_history(session_id, user_id)
    while True:
        print("-" * 20)
        user_input = input("üë§ B·∫°n h·ªèi (ho·∫∑c g√µ 'pdf'): ")
        if user_input.lower() == "exit":
            print("T·∫°m bi·ªát!")
            break
        if user_input.lower() == "pdf":
            pdf_path = input("üìÇ Nh·∫≠p ƒë∆∞·ªùng d·∫´n PDF: ").strip()
            if pdf_path and os.path.exists(pdf_path):
                handle_pdf_upload(pdf_path, session_id, user_id)
            else:
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file t·∫°i '{pdf_path}'")
            continue
        query_text = user_input
        image_path = input("üñºÔ∏è Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh (Enter n·∫øu kh√¥ng c√≥): ").strip()
        print("\nüí° Tr·∫£ l·ªùi:")
        if image_path and os.path.exists(image_path):
            handle_multimodal_query(query_text, image_path, user_id, session_id)
        elif image_path:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh t·∫°i '{image_path}'")
        else:
            handle_text_query(query_text, user_id, session_id)


if __name__ == "__main__":
    main()  # Mai v√†o Grok copy r·ªìi s·ª≠a logic (vision + file pdf)
